{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFD æ·±åº¦å­¦ä¹ è®­ç»ƒ - Jupyter Notebook å¯åŠ¨è„šæœ¬\n",
    "\n",
    "## ä½¿ç”¨è¯´æ˜\n",
    "1. ç¡®ä¿é€‰æ‹©äº†æ­£ç¡®çš„ Kernel: **Python (CFD Environment)**\n",
    "2. æŒ‰é¡ºåºè¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼\n",
    "3. è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥éšæ—¶ä¸­æ–­ (Kernel â†’ Interrupt)\n",
    "4. å…³é—­æµè§ˆå™¨ä¸ä¼šå½±å“è®­ç»ƒï¼Œåªè¦ Jupyter Kernel è¿˜åœ¨è¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. éªŒè¯ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python è·¯å¾„: /home/jovyan/teaching_material/Work/December/ai_cfd/cfd_env/bin/python\n",
      "å½“å‰ç›®å½•: /home/jovyan/teaching_material/Work/December/ai_cfd\n",
      "PyTorch ç‰ˆæœ¬: 2.3.1+cu121\n",
      "CUDA å¯ç”¨: True\n",
      "GPU å‹å·: NVIDIA A40\n",
      "æ˜¾å­˜å¤§å°: 44.55 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(f\"Python è·¯å¾„: {os.sys.executable}\")\n",
    "print(f\"å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU å‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"æ˜¾å­˜å¤§å°: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ£€æŸ¥æ•°æ®æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰¾åˆ° 7 ä¸ªæ•°æ®æ–‡ä»¶:\n",
      "  - 340.npy: 1.72 GB\n",
      "  - 370.npy: 1.72 GB\n",
      "  - 400.npy: 1.72 GB\n",
      "  - 430.npy: 1.72 GB\n",
      "  - 460.npy: 1.72 GB\n",
      "  - 490.npy: 1.72 GB\n",
      "  - 520.npy: 1.72 GB\n",
      "\n",
      "æ•°æ®å½¢çŠ¶: (6001, 200, 128, 3)\n",
      "æ•°æ®ç±»å‹: float32\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "data_files = sorted(glob.glob('./processed_data/*.npy'))\n",
    "print(f\"æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶:\")\n",
    "for f in data_files:\n",
    "    size_gb = os.path.getsize(f) / 1024**3\n",
    "    print(f\"  - {os.path.basename(f)}: {size_gb:.2f} GB\")\n",
    "\n",
    "# å¿«é€Ÿæ£€æŸ¥ä¸€ä¸ªæ–‡ä»¶\n",
    "if data_files:\n",
    "    test_data = np.load(data_files[0], mmap_mode='r')\n",
    "    print(f\"\\næ•°æ®å½¢çŠ¶: {test_data.shape}\")\n",
    "    print(f\"æ•°æ®ç±»å‹: {test_data.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ–¹å¼ Aï¼šç›´æ¥è¿è¡Œè®­ç»ƒè„šæœ¬ï¼ˆæ¨èï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨ä½¿ç”¨è®¡ç®—è®¾å¤‡: cuda\n",
      "ğŸ”¥ æ˜¾å¡å‹å·: NVIDIA A40\n",
      "ğŸ“Š æ˜¾å­˜æ€»é‡: 44.55 GB\n",
      "============================================================\n",
      "CFD æ·±åº¦å­¦ä¹ è®­ç»ƒç³»ç»Ÿ\n",
      "============================================================\n",
      "\n",
      "[1/4] å‡†å¤‡æ•°æ®é›†...\n",
      "ğŸ“‚ æ­£åœ¨å»ºç«‹æ•°æ®ç´¢å¼• (ä½¿ç”¨å†…å­˜æ˜ å°„ï¼Œä¸ä¼šçˆ†å†…å­˜)...\n",
      "  âœ“ 340.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "  âœ“ 370.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "  âœ“ 400.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "  âœ“ 430.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "  âœ“ 460.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "  âœ“ 490.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "  âœ“ 520.npy: (6001, 200, 128, 3), 6000 ä¸ªè®­ç»ƒæ ·æœ¬\n",
      "âœ… æ•°æ®é›†å°±ç»ªï¼å…± 7 ä¸ªåˆ‡ç‰‡ï¼ŒåŒ…å« 42000 ä¸ªè®­ç»ƒæ ·æœ¬ã€‚\n",
      "\n",
      "[2/4] åˆå§‹åŒ–æ¨¡å‹...\n",
      "âœ… å·²åŠ è½½ Epoch 10 æƒé‡ï¼Œç»§ç»­è®­ç»ƒ...\n",
      "ğŸ“Š æ¨¡å‹å‚æ•°é‡: 5,752,835 (å¯è®­ç»ƒ: 5,752,835)\n",
      "\n",
      "[3/4] æ£€æŸ¥æ–­ç‚¹...\n",
      "ğŸ“¥ å·²åŠ è½½æ£€æŸ¥ç‚¹: ./checkpoints/resnet_epoch_10.pth\n",
      "   ä» Epoch 10 ç»§ç»­è®­ç»ƒ\n",
      "\n",
      "[4/4] å¼€å§‹è®­ç»ƒï¼\n",
      "   æ‰¹æ¬¡å¤§å°: 16\n",
      "   å­¦ä¹ ç‡: 1e-05\n",
      "   è®­ç»ƒè½®æ•°: 100\n",
      "   èµ·å§‹ Epoch: 10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.95it/s, Loss=0.000093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/100 å®Œæˆ | å¹³å‡ Loss: 0.00308296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.94it/s, Loss=0.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/100 å®Œæˆ | å¹³å‡ Loss: 0.00013552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.90it/s, Loss=0.000157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/100 å®Œæˆ | å¹³å‡ Loss: 0.00011346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.91it/s, Loss=0.000044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/100 å®Œæˆ | å¹³å‡ Loss: 0.00008988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:58<00:00, 22.06it/s, Loss=0.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/100 å®Œæˆ | å¹³å‡ Loss: 0.00007096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.02it/s, Loss=0.000034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/100 å®Œæˆ | å¹³å‡ Loss: 0.00006185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.95it/s, Loss=0.000112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/100 å®Œæˆ | å¹³å‡ Loss: 0.00005037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.94it/s, Loss=0.000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/100 å®Œæˆ | å¹³å‡ Loss: 0.00004582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.97it/s, Loss=0.000009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/100 å®Œæˆ | å¹³å‡ Loss: 0.00003998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.89it/s, Loss=0.000054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100 å®Œæˆ | å¹³å‡ Loss: 0.00005944\n",
      "ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: ./checkpoints/resnet_epoch_20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.96it/s, Loss=0.000030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/100 å®Œæˆ | å¹³å‡ Loss: 0.00003844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.92it/s, Loss=0.000012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/100 å®Œæˆ | å¹³å‡ Loss: 0.00003343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.01it/s, Loss=0.000013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/100 å®Œæˆ | å¹³å‡ Loss: 0.00003052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.96it/s, Loss=0.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/100 å®Œæˆ | å¹³å‡ Loss: 0.00002868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.92it/s, Loss=0.000008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/100 å®Œæˆ | å¹³å‡ Loss: 0.00002653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.00it/s, Loss=0.000009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/100 å®Œæˆ | å¹³å‡ Loss: 0.00002739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.88it/s, Loss=0.000006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/100 å®Œæˆ | å¹³å‡ Loss: 0.00002507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.91it/s, Loss=0.000020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/100 å®Œæˆ | å¹³å‡ Loss: 0.00002446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2539/2625 [01:55<00:03, 22.21it/s, Loss=0.000148]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 37/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.92it/s, Loss=0.000003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/100 å®Œæˆ | å¹³å‡ Loss: 0.00002191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.98it/s, Loss=0.000002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/100 å®Œæˆ | å¹³å‡ Loss: 0.00002191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.98it/s, Loss=0.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100 å®Œæˆ | å¹³å‡ Loss: 0.00002196\n",
      "ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: ./checkpoints/resnet_epoch_40.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100:   8%|â–Š         | 205/2625 [00:09<01:51, 21.69it/s, Loss=0.000010]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 47/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.00it/s, Loss=0.000012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/100 å®Œæˆ | å¹³å‡ Loss: 0.00002128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.01it/s, Loss=0.000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/100 å®Œæˆ | å¹³å‡ Loss: 0.00002137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:58<00:00, 22.07it/s, Loss=0.000009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/100 å®Œæˆ | å¹³å‡ Loss: 0.00002156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.97it/s, Loss=0.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51/100 å®Œæˆ | å¹³å‡ Loss: 0.00002135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1081/2625 [00:49<01:09, 22.24it/s, Loss=0.000001]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 58/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:58<00:00, 22.08it/s, Loss=0.000002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58/100 å®Œæˆ | å¹³å‡ Loss: 0.00002116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.05it/s, Loss=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59/100 å®Œæˆ | å¹³å‡ Loss: 0.00002111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:58<00:00, 22.06it/s, Loss=0.000004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100 å®Œæˆ | å¹³å‡ Loss: 0.00002097\n",
      "ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: ./checkpoints/resnet_epoch_60.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1837/2625 [01:23<00:36, 21.86it/s, Loss=0.000001]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 68/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.00it/s, Loss=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68/100 å®Œæˆ | å¹³å‡ Loss: 0.00002120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.01it/s, Loss=0.000223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69/100 å®Œæˆ | å¹³å‡ Loss: 0.00002092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1867/2625 [01:25<00:34, 22.14it/s, Loss=0.000005]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 79/100:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2302/2625 [01:44<00:14, 22.16it/s, Loss=0.000005]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 87/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.02it/s, Loss=0.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87/100 å®Œæˆ | å¹³å‡ Loss: 0.00002122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1927/2625 [01:27<00:31, 22.27it/s, Loss=0.000001]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 94/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 22.02it/s, Loss=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94/100 å®Œæˆ | å¹³å‡ Loss: 0.00002090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2625/2625 [01:59<00:00, 21.99it/s, Loss=0.000118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96/100 å®Œæˆ | å¹³å‡ Loss: 0.00002089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1363/2625 [01:01<00:56, 22.23it/s, Loss=0.000001]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ç›´æ¥è¿è¡Œ train.py\n",
    "# è¿™ä¸ªå•å…ƒæ ¼ä¼šè¿è¡Œå®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹\n",
    "# å¯ä»¥éšæ—¶ç”¨ Kernel â†’ Interrupt ä¸­æ–­\n",
    "\n",
    "%run train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ–¹å¼ Bï¼šäº¤äº’å¼è®­ç»ƒï¼ˆå¯ä»¥å•æ­¥è°ƒè¯•ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœæƒ³è¦æ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œå¯ä»¥åˆ†æ­¥æ‰§è¡Œ\n",
    "# è¿™å…è®¸ä½ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ’å…¥è‡ªå®šä¹‰ä»£ç \n",
    "\n",
    "# åŠ è½½è®­ç»ƒæ¨¡å—\n",
    "import sys\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# å¯¼å…¥è®­ç»ƒä»£ç ä¸­çš„ç±»å’Œå‡½æ•°\n",
    "from train import CFDDataset, CFDPredictor, device, BATCH_SIZE, LEARNING_RATE, EPOCHS, DATA_DIR, SAVE_DIR\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm  # Notebook ç‰ˆæœ¬çš„è¿›åº¦æ¡\n",
    "\n",
    "print(\"âœ… æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")\n",
    "print(f\"   è®¾å¤‡: {device}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   å­¦ä¹ ç‡: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®é›†\n",
    "dataset = CFDDataset(DATA_DIR)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼å…± {len(dataset)} ä¸ªæ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = CFDPredictor().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼\")\n",
    "print(f\"   å‚æ•°é‡: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå¾ªç¯ï¼ˆå¯ä»¥åªè®­ç»ƒå‡ ä¸ª epoch æµ‹è¯•ï¼‰\n",
    "test_epochs = 5  # å…ˆæµ‹è¯• 5 ä¸ª epoch\n",
    "\n",
    "for epoch in range(test_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # ä½¿ç”¨ notebook ç‰ˆæœ¬çš„ tqdm\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{test_epochs}\")\n",
    "\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'Loss': f\"{loss.item():.6f}\"})\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1} å¹³å‡ Loss: {avg_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç›‘æ§ GPU çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ£€æŸ¥è®­ç»ƒè¿›åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹å·²ä¿å­˜çš„æ£€æŸ¥ç‚¹\n",
    "checkpoints = sorted(glob.glob('./checkpoints/*.pth'))\n",
    "print(f\"å·²ä¿å­˜ {len(checkpoints)} ä¸ªæ£€æŸ¥ç‚¹:\")\n",
    "for ckpt in checkpoints:\n",
    "    size_mb = os.path.getsize(ckpt) / 1024**2\n",
    "    print(f\"  - {os.path.basename(ckpt)}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æç¤º\n",
    "\n",
    "- **æ–¹å¼ Aï¼ˆæ¨èï¼‰**: ç›´æ¥è¿è¡Œ `%run train.py`ï¼Œé€‚åˆå®Œæ•´è®­ç»ƒ\n",
    "- **æ–¹å¼ B**: åˆ†æ­¥æ‰§è¡Œï¼Œé€‚åˆè°ƒè¯•å’Œå®éªŒ\n",
    "- **ä¸­æ–­è®­ç»ƒ**: ä½¿ç”¨ `Kernel â†’ Interrupt` æˆ–ç‚¹å‡»åœæ­¢æŒ‰é’®\n",
    "- **åå°è¿è¡Œ**: åªè¦ Kernel ä¸é‡å¯ï¼Œå…³é—­æµè§ˆå™¨ä¸å½±å“è®­ç»ƒ\n",
    "- **ç›‘æ§**: å¯ä»¥åœ¨ç»ˆç«¯ç”¨ `watch -n 1 nvidia-smi` å®æ—¶ç›‘æ§ GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CFD Environment)",
   "language": "python",
   "name": "cfd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
