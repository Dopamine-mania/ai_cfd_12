import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from train import CFDPredictor  # ä»è®­ç»ƒä»£ç å¯¼å…¥æ¨¡å‹ç»“æ„
import os

# ================= é…ç½® =================
# å¯ç”¨ç¯å¢ƒå˜é‡ MODEL_PATH æŒ‡å®šæƒé‡æ–‡ä»¶ï¼Œä¾¿äºåˆ‡æ¢å¾®è°ƒåçš„ checkpoint
MODEL_PATH = os.getenv('MODEL_PATH', './checkpoints/resnet_epoch_100.pth')  # ä½¿ç”¨100è½®è®­ç»ƒçš„å®Œæ•´checkpoint
_DEFAULT_DATA_PATH = './processed_data/26ms/340.npy' if os.path.exists('./processed_data/26ms/340.npy') else './processed_data/340.npy'
DATA_PATH = os.getenv('DATA_PATH', _DEFAULT_DATA_PATH) # X=340ä½ç½®çš„æˆªé¢æ•°æ®
SAVE_GIF = os.getenv('SAVE_GIF', './results/prediction_9s.gif')  # 9ç§’é¢„æµ‹ç»“æœ
SAVE_ERROR_CURVE = os.getenv('SAVE_ERROR_CURVE', './results/error_curve_9s.png')  # è¯¯å·®æ›²çº¿
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# 9ç§’é¢„æµ‹ (Î”t=2ms). å¯ç”¨ç¯å¢ƒå˜é‡ PRED_STEPS è¦†ç›–ï¼Œä¾¿äºå¿«é€Ÿè°ƒè¯•
PRED_STEPS = int(os.getenv('PRED_STEPS', '4500'))

# å½’ä¸€åŒ–åçš„åˆç†ç‰©ç†èŒƒå›´ (ç”¨äºé’³åˆ¶é˜²æ­¢æº¢å‡º/å‘æ•£)
CLAMP_MIN = float(os.getenv('CLAMP_MIN', '-0.5'))
CLAMP_MAX = float(os.getenv('CLAMP_MAX', '1.5'))
CLAMP_MODE = os.getenv('CLAMP_MODE', 'hard').lower()  # hard | smooth(softplus) | soft(tanh)
# alpha æ§åˆ¶ soft clamp åœ¨ä¸­éƒ¨çš„â€œæ–œç‡â€ï¼šå¯¼æ•°çº¦ä¸º 1/alphaã€‚
# - alpha=1ï¼šä¸­éƒ¨è¿‘ä¼¼æ’ç­‰æ˜ å°„ï¼ˆä¸å‹ç¼©ç»†èŠ‚ï¼‰ï¼Œè¾¹ç•Œå¤„å¹³æ»‘é¥±å’Œï¼ˆæ¨èï¼Œä¸”ä¸è®­ç»ƒç«¯ä¸€è‡´ï¼‰
# - alpha>1ï¼šä¼šæŠŠåœºæ‹‰å‘ midï¼ˆå¯èƒ½é€ æˆâ€œå‘ç°/å˜å¹³â€ï¼‰
SOFT_CLAMP_ALPHA = float(os.getenv('SOFT_CLAMP_ALPHA', '1.0'))
SMOOTH_CLAMP_BETA = float(os.getenv('SMOOTH_CLAMP_BETA', '200.0'))  # è¶Šå¤§è¶Šæ¥è¿‘ hard clampï¼Œä¸”åŒºé—´å†…æ›´æ¥è¿‘æ’ç­‰

# ç©ºé—´æ»¤æ³¢ (Gaussian Smoothing): å¼ºæ•ˆä½é€šï¼ŒæŠ‘åˆ¶èŠ±å±é«˜é¢‘éœ‡è¡
# å¾®è°ƒæ–¹æ¡ˆä¸‹é»˜è®¤å…³é—­ï¼›éœ€è¦æ—¶å†é€šè¿‡ GAUSS_ENABLE=1 æ‰“å¼€
GAUSS_ENABLE = int(os.getenv('GAUSS_ENABLE', '0'))
GAUSS_BLEND = float(os.getenv('GAUSS_BLEND', '0.8'))  # 0.8*å¹³æ»‘ + 0.2*åŸå›¾
GAUSS_START_STEP = int(os.getenv('GAUSS_START_STEP', '3500'))  # ä»ç¬¬å‡ æ­¥å¼€å§‹å¯ç”¨(é»˜è®¤åæ®µå¯ç”¨ä»¥ä¿ç»†èŠ‚)

# ================= ç‰©ç†ç¡¬çº¦æŸï¼ˆæ¨ç†ç«¯ï¼‰ =================
# 1) èˆ¹ä½“/æ­»æ°´åŒº Maskï¼šä» t=0 è‡ªåŠ¨ä¼°è®¡ï¼Œå¹¶åœ¨æ»šåŠ¨é¢„æµ‹ä¸­é”æ­»ï¼ˆä¸è®©æ¨¡å‹é¢„æµ‹èˆ¹ä½“ï¼‰ã€‚
MASK_ENABLE = int(os.getenv('MASK_ENABLE', '1'))
MASK_MODE = os.getenv('MASK_MODE', 'u').lower()  # u | speed
MASK_U_THRESHOLD = float(os.getenv('MASK_U_THRESHOLD', '0.2'))  # åœ¨å½’ä¸€åŒ–ç©ºé—´ (u/30)
MASK_SPEED_THRESHOLD = float(os.getenv('MASK_SPEED_THRESHOLD', '0.2'))  # åœ¨å½’ä¸€åŒ–ç©ºé—´ (|v|/30)
MASK_LEFT_COLS = int(os.getenv('MASK_LEFT_COLS', '24'))  # åªåœ¨å·¦ä¾§è‹¥å¹²åˆ—é‡Œæ‰¾ maskï¼Œé¿å…è¯¯é” wake
MASK_LOCK = os.getenv('MASK_LOCK', 'initial').lower()  # initial | zero

# 2) å¼€æ”¾è¾¹ç•Œ Dirichletï¼šæ¯ä¸€æ­¥æŠŠè¿œåœºè¾¹ç¼˜åƒç´ é‡ç½®ä¸º t=0 çš„èƒŒæ™¯æµåœºå€¼ï¼ˆç±»ä¼¼æµ·ç»µå±‚ç¡¬è¾¹ç•Œï¼‰
BC_ENABLE = int(os.getenv('BC_ENABLE', '1'))
BC_PAD_RIGHT = int(os.getenv('BC_PAD_RIGHT', '4'))
BC_PAD_TOP = int(os.getenv('BC_PAD_TOP', '4'))
BC_PAD_BOTTOM = int(os.getenv('BC_PAD_BOTTOM', '4'))

# æ•°å€¼é˜»å°¼ (Numerical Damping): next = (1-d)*pred + d*prev
# å¯ç”¨ç¯å¢ƒå˜é‡ DAMPING è¦†ç›– (0~1)ï¼Œd è¶Šå¤§è¶Šå¹³æ»‘/æ›´ç¨³å®šä½†æ›´â€œç²˜â€
# å¾®è°ƒæ–¹æ¡ˆä¸‹é»˜è®¤å…³é—­ï¼›éœ€è¦æ—¶å†é€šè¿‡ DAMPING=0.05~0.2 æ‰“å¼€
DAMPING = float(os.getenv('DAMPING', '0.0'))

# å¯å¯¼è½¯é’³åˆ¶ï¼šé¿å…ç¡¬æˆªæ–­é€ æˆâ€œå¤§è‰²å—/æ­»é”æ„Ÿâ€ï¼ŒåŒæ—¶ä»ä¿è¯è½åœ¨ç‰©ç†åŒºé—´
def soft_clamp_tanh(x, min_val, max_val, alpha):
    mid = (max_val + min_val) * 0.5
    half = (max_val - min_val) * 0.5
    denom = max(half * max(alpha, 1e-6), 1e-6)
    return mid + half * torch.tanh((x - mid) / denom)

def smooth_clamp_softplus(x, min_val, max_val, beta):
    """
    æ›´é€‚åˆâ€œè§†è§‰ä¿çœŸâ€çš„è½¯é’³åˆ¶ï¼šåŒºé—´å†…è¿‘ä¼¼æ’ç­‰ï¼Œè¶Šç•Œåå¹³æ»‘é¥±å’Œåˆ°è¾¹ç•Œã€‚
    y = x + softplus(min-x) - softplus(x-max)
    """
    beta = max(float(beta), 1e-6)
    return x + F.softplus(min_val - x, beta=beta, threshold=20.0) - F.softplus(x - max_val, beta=beta, threshold=20.0)

def apply_physical_bound(x):
    if CLAMP_MODE in ('soft', 'tanh'):
        return soft_clamp_tanh(x, CLAMP_MIN, CLAMP_MAX, SOFT_CLAMP_ALPHA)
    if CLAMP_MODE == 'smooth':
        return smooth_clamp_softplus(x, CLAMP_MIN, CLAMP_MAX, SMOOTH_CLAMP_BETA)
    if CLAMP_MODE == 'hard':
        return torch.clamp(x, min=CLAMP_MIN, max=CLAMP_MAX)
    raise ValueError(f"æœªçŸ¥ CLAMP_MODE={CLAMP_MODE}ï¼ŒæœŸæœ› hard|soft|smooth")

def compute_hull_mask(initial_tensor):
    """
    initial_tensor: (1,3,H,W) å½’ä¸€åŒ–åçš„åˆå§‹å¸§
    è¿”å›: (1,1,H,W) bool maskï¼ˆTrue è¡¨ç¤ºé”å®šåŒºåŸŸï¼‰
    """
    if not MASK_ENABLE:
        return None

    _, _, h, w = initial_tensor.shape
    left_cols = max(0, min(int(MASK_LEFT_COLS), w))
    if left_cols <= 0:
        return None

    if MASK_MODE == 'u':
        u0 = initial_tensor[:, 0:1, :, :]  # (1,1,H,W)
        low = u0 < MASK_U_THRESHOLD
    elif MASK_MODE == 'speed':
        speed0 = torch.linalg.vector_norm(initial_tensor, dim=1, keepdim=True)  # (1,1,H,W)
        low = speed0 < MASK_SPEED_THRESHOLD
    else:
        raise ValueError(f"æœªçŸ¥ MASK_MODE={MASK_MODE}ï¼ŒæœŸæœ› u|speed")

    region = torch.zeros((1, 1, h, w), device=initial_tensor.device, dtype=torch.bool)
    region[:, :, :, :left_cols] = True
    return low & region

def apply_hard_constraints(x, initial_tensor, hull_mask):
    """
    x: (1,3,H,W) å½“å‰é¢„æµ‹
    initial_tensor: (1,3,H,W) t=0 å½’ä¸€åŒ–åˆå§‹å¸§ï¼ˆç”¨äº Dirichlet BC ä¸ mask é”å®šï¼‰
    hull_mask: (1,1,H,W) bool æˆ– None
    """
    # è¿œåœºè¾¹ç•Œ Dirichletï¼šå³/ä¸Š/ä¸‹
    if BC_ENABLE:
        if BC_PAD_RIGHT > 0:
            x[:, :, :, -BC_PAD_RIGHT:] = initial_tensor[:, :, :, -BC_PAD_RIGHT:]
        if BC_PAD_TOP > 0:
            x[:, :, :BC_PAD_TOP, :] = initial_tensor[:, :, :BC_PAD_TOP, :]
        if BC_PAD_BOTTOM > 0:
            x[:, :, -BC_PAD_BOTTOM:, :] = initial_tensor[:, :, -BC_PAD_BOTTOM:, :]

    # èˆ¹ä½“/æ­»æ°´åŒºé”å®š
    if hull_mask is not None:
        if MASK_LOCK == 'zero':
            lock_val = torch.zeros_like(x)
        elif MASK_LOCK == 'initial':
            lock_val = initial_tensor
        else:
            raise ValueError(f"æœªçŸ¥ MASK_LOCK={MASK_LOCK}ï¼ŒæœŸæœ› initial|zero")
        x = torch.where(hull_mask.expand_as(x), lock_val, x)

    return x

# å›ºå®š 3x3 é«˜æ–¯æ ¸ (ä½é€šæ»¤æ³¢å™¨)ï¼Œå¯¹ 3 é€šé“åš depthwise conv
GAUSS_KERNEL_3x3 = torch.tensor(
    [[1.0, 2.0, 1.0],
     [2.0, 4.0, 2.0],
     [1.0, 2.0, 1.0]],
    device=DEVICE,
    dtype=torch.float32,
) / 16.0
GAUSS_KERNEL_3x3 = GAUSS_KERNEL_3x3.view(1, 1, 3, 3).repeat(3, 1, 1, 1)

if not os.path.exists('./results'):
    os.makedirs('./results')

# 1. åŠ è½½æ¨¡å‹
print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
model = CFDPredictor().to(DEVICE)
# # å¦‚æœ final è¿˜æ²¡è·‘å®Œï¼Œä½ å¯ä»¥æ‰‹åŠ¨æ”¹è¿™é‡ŒåŠ è½½ä¸­é—´çš„ checkpointï¼Œæ¯”å¦‚ resnet_epoch_10.pth
# if os.path.exists(MODEL_PATH):
#     model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
#     print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼")
# else:
#     print(f"âš ï¸ æ‰¾ä¸åˆ° {MODEL_PATH}ï¼Œè¯·ç­‰å¾…è®­ç»ƒç»“æŸæˆ–ä¿®æ”¹è·¯å¾„åŠ è½½ä¸­é—´æƒé‡ã€‚")
#     exit()
print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)

# --- æ ¸å¿ƒä¿®æ”¹å¼€å§‹ ---
if 'model_state_dict' in checkpoint:
    # æƒ…å†µ A: å¦‚æœæ˜¯åŒ…å«äº† epoch, loss ç­‰ä¿¡æ¯çš„â€œå¤§ç¤¼åŒ…â€
    print("ğŸ“¦ æ£€æµ‹åˆ°åŒ…å«å…ƒæ•°æ®çš„æ¨¡å‹æ–‡ä»¶ï¼Œæ­£åœ¨æå–æƒé‡...")
    model.load_state_dict(checkpoint['model_state_dict'])
else:
    # æƒ…å†µ B: å¦‚æœåªæ˜¯å•çº¯çš„æƒé‡æ–‡ä»¶
    print("ğŸ“„ æ£€æµ‹åˆ°çº¯æƒé‡æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½...")
    model.load_state_dict(checkpoint)
# --- æ ¸å¿ƒä¿®æ”¹ç»“æŸ ---

print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼")

model.eval()

# 2. åŠ è½½æµ‹è¯•æ•°æ®
print("ğŸ“‚ è¯»å–æµ‹è¯•æ•°æ®...")
# ä½¿ç”¨ mmap é¿å…ä¸€æ¬¡æ€§è¯»å…¥å†…å­˜
data = np.load(DATA_PATH, mmap_mode='r') # (6001, 200, 128, 3) -> [æ—¶é—´, Y, Z, (U,V,W)]
# å–å‰ (PRED_STEPS+1) å¸§ç”¨äºé¢„æµ‹ (åˆå§‹å¸§ + PRED_STEPS æ­¥é¢„æµ‹)
test_seq = data[: PRED_STEPS + 1]
print(f"âœ… æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_seq.shape}") 

# 3. æ»šåŠ¨é¢„æµ‹ (Rolling Prediction)
# ä¹Ÿå°±æ˜¯ï¼šç”¨ç¬¬1å¸§é¢„æµ‹ç¬¬2å¸§ï¼Œç”¨é¢„æµ‹å‡ºçš„ç¬¬2å¸§é¢„æµ‹ç¬¬3å¸§... (è¿™æ˜¯æœ€éš¾çš„ï¼Œçœ‹AIä¼šä¸ä¼šå´©)
print("ğŸ”® å¼€å§‹æ»šåŠ¨é¢„æµ‹ (è‡ªå›å½’æµ‹è¯•)...")
current_frame = test_seq[0] # åˆå§‹æ¡ä»¶ (H, W, 3)

# å½’ä¸€åŒ–
current_tensor = torch.from_numpy(current_frame / 30.0).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE)
initial_tensor = current_tensor.clone()
hull_mask = compute_hull_mask(initial_tensor)
if hull_mask is not None:
    mask_ratio = hull_mask.float().mean().item()
    print(f"ğŸ§± Hull mask: mode={MASK_MODE}, lock={MASK_LOCK}, left_cols={MASK_LEFT_COLS}, ratio={mask_ratio:.4f}")
if BC_ENABLE:
    print(f"ğŸ§· Dirichlet BC: right={BC_PAD_RIGHT}px, top={BC_PAD_TOP}px, bottom={BC_PAD_BOTTOM}px (reset to t=0)")

# ä¸ºäº†é¿å…å­˜ä¸‹ 4501 å¸§(å ç”¨æ•°GBå†…å­˜)ï¼Œè¿™é‡ŒæŒ‰ stride åªç¼“å­˜ GIF éœ€è¦çš„å¸§ï¼›
# è¯¯å·®æ›²çº¿åˆ™æŒ‰æ­¥åœ¨çº¿è®¡ç®—ã€‚
GIF_STRIDE = int(os.getenv('GIF_STRIDE', '25'))  # çº¦ 9s@20fps -> 180å¸§å·¦å³
gif_steps = list(range(0, PRED_STEPS + 1, max(GIF_STRIDE, 1)))
if gif_steps[-1] != PRED_STEPS:
    gif_steps.append(PRED_STEPS)
gif_step_set = set(gif_steps)
gif_truth_u = {0: test_seq[0, :, :, 0]}
gif_pred_u = {0: test_seq[0, :, :, 0]}
errors = [0.0]  # t=0: é¢„æµ‹ç­‰äºåˆå€¼

print(f"å¼€å§‹ {PRED_STEPS} æ­¥æ»šåŠ¨é¢„æµ‹ (9ç§’ @ Î”t=2ms)...")
with torch.no_grad():
    for t in range(PRED_STEPS):
        # 1. é¢„æµ‹
        next_tensor = model(current_tensor)
        step_idx = t + 1

        # 2. ç‰©ç†çº¦æŸä¸é˜»å°¼
        # A) å…ˆåšèŒƒå›´çº¦æŸï¼ˆé˜²æ­¢æ•°å€¼çˆ†æ‰å½±å“åç»­å·ç§¯/æ··åˆï¼‰
        next_tensor = apply_physical_bound(next_tensor)

        # B) ç©ºé—´é«˜æ–¯æ»¤æ³¢: å¼ºæ•ˆä½é€šï¼Œæ»¤é™¤èŠ±å±é«˜é¢‘å™ªç‚¹ï¼ˆç±»ä¼¼ LES è¿‡æ»¤ï¼‰
        if GAUSS_ENABLE and step_idx >= GAUSS_START_STEP:
            kernel = GAUSS_KERNEL_3x3.to(device=next_tensor.device, dtype=next_tensor.dtype)
            next_smoothed = F.conv2d(next_tensor, kernel, padding=1, groups=3)
            next_tensor = GAUSS_BLEND * next_smoothed + (1.0 - GAUSS_BLEND) * next_tensor

        # C) æ•°å€¼é˜»å°¼: æ—¶é—´æ–¹å‘æƒ¯æ€§å¹³æ»‘ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 0.1ï¼‰
        if DAMPING > 0:
            next_tensor = (1.0 - DAMPING) * next_tensor + DAMPING * current_tensor

        # D) èˆ¹ä½“ mask é”å®š + è¿œåœº Dirichlet è¾¹ç•Œï¼ˆç¡¬çº¦æŸï¼ŒæŠ‘åˆ¶è¯¯å·®ä»è¾¹ç¼˜å€’çŒï¼‰
        next_tensor = apply_hard_constraints(next_tensor, initial_tensor, hull_mask)

        # E) å†çº¦æŸä¸€æ¬¡ï¼Œé¿å…æ··åˆ/é‡ç½®åä»è¶Šç•Œ
        next_tensor = apply_physical_bound(next_tensor)

        # 3. è½¬å› numpy (ç‰©ç†é‡å•ä½)
        pred_np = next_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy() * 30.0
        # 4. åœ¨çº¿è®¡ç®—è¯¯å·® (L2 ç›¸å¯¹è¯¯å·®)
        truth_np = test_seq[step_idx]
        diff_norm = np.linalg.norm(pred_np - truth_np)
        truth_norm = np.linalg.norm(truth_np)
        errors.append(diff_norm / truth_norm)

        # 5. ä»…ç¼“å­˜ GIF éœ€è¦çš„å¸§ (U åˆ†é‡)
        if step_idx in gif_step_set:
            gif_truth_u[step_idx] = truth_np[:, :, 0]
            gif_pred_u[step_idx] = pred_np[:, :, 0]

        # 6. æ›´æ–°è¾“å…¥
        current_tensor = next_tensor

        # 7. è¿›åº¦æ˜¾ç¤º
        if (t + 1) % 500 == 0:
            print(f"  Step {t+1}/{PRED_STEPS}: Max={next_tensor.max().item():.3f}, Min={next_tensor.min().item():.3f}")

errors = np.array(errors)
print(f"âœ… é¢„æµ‹å®Œæˆï¼")
print(f"âœ… è¯¯å·®è®¡ç®—å®Œæˆï¼")
print(f"   å¹³å‡ç›¸å¯¹è¯¯å·®: {errors.mean():.6f}")
print(f"   æœ€å¤§ç›¸å¯¹è¯¯å·®: {errors.max():.6f}")
print(f"   æœ€ç»ˆæ—¶åˆ»è¯¯å·®: {errors[-1]:.6f}")

# 5. ç”»å›¾åˆ¶ä½œ GIF
print("ğŸ¨ æ­£åœ¨æ¸²æŸ“ GIF (å·¦: çœŸå®, å³: é¢„æµ‹)...")
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

vmin, vmax = test_seq[:, :, :, 0].min(), test_seq[:, :, :, 0].max()

def update(frame_i):
    for ax in axes: ax.clear()

    step_idx = gif_steps[frame_i]
    # å– U é€Ÿåº¦ (Xæ–¹å‘) å±•ç¤º
    real_u = gif_truth_u[step_idx]
    pred_u = gif_pred_u[step_idx]
    
    axes[0].imshow(real_u, cmap='jet', vmin=vmin, vmax=vmax)
    axes[0].set_title(f"Ground Truth (step={step_idx}, t={step_idx*0.002:.3f}s)")
    axes[0].axis('off')
    
    axes[1].imshow(pred_u, cmap='jet', vmin=vmin, vmax=vmax)
    axes[1].set_title(f"AI Prediction (step={step_idx}, t={step_idx*0.002:.3f}s)")
    axes[1].axis('off')

ani = animation.FuncAnimation(fig, update, frames=len(gif_steps), interval=50)
ani.save(SAVE_GIF, writer='pillow', fps=20)
plt.close(fig)

print(f"ğŸ‰ åŠ¨å›¾å·²ä¿å­˜è‡³: {SAVE_GIF}")

# 6. ç»˜åˆ¶è¯¯å·®æ›²çº¿å›¾
print("ğŸ“ˆ ç»˜åˆ¶è¯¯å·®æ›²çº¿...")
fig, ax = plt.subplots(figsize=(10, 6))

# æ—¶é—´è½´ (ç§’)
time_axis = np.arange(len(errors)) * 0.002  # Î”t = 2ms = 0.002s

# ç»˜åˆ¶è¯¯å·®æ›²çº¿
ax.plot(time_axis, errors, linewidth=2, color='#E74C3C', label='L2 Relative Error')
ax.axhline(y=errors.mean(), color='#3498DB', linestyle='--', linewidth=1.5,
           label=f'Mean Error = {errors.mean():.6f}')

# è®¾ç½®å›¾è¡¨
ax.set_xlabel('Time (s)', fontsize=14, fontweight='bold')
ax.set_ylabel('Relative L2 Error', fontsize=14, fontweight='bold')
ax.set_title('Long-term Prediction Error Evolution (9s @ Î”t=2ms)',
             fontsize=16, fontweight='bold', pad=20)
ax.grid(True, alpha=0.3, linestyle='--')
ax.legend(fontsize=12, loc='upper left')

# æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
textstr = f'Statistics:\n' \
          f'Mean Error: {errors.mean():.6f}\n' \
          f'Max Error: {errors.max():.6f}\n' \
          f'Final Error: {errors[-1]:.6f}\n' \
          f'Prediction Steps: {PRED_STEPS}'
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
ax.text(0.98, 0.97, textstr, transform=ax.transAxes, fontsize=11,
        verticalalignment='top', horizontalalignment='right', bbox=props)

plt.tight_layout()
plt.savefig(SAVE_ERROR_CURVE, dpi=300, bbox_inches='tight')
plt.close(fig)

print(f"ğŸ‰ è¯¯å·®æ›²çº¿å·²ä¿å­˜è‡³: {SAVE_ERROR_CURVE}")
print("\n" + "="*60)
print("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
print("="*60)
print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶:")
print(f"   1. é¢„æµ‹åŠ¨å›¾: {SAVE_GIF}")
print(f"   2. è¯¯å·®æ›²çº¿: {SAVE_ERROR_CURVE}")
print("="*60)
